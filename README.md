 âœ‹ Sign Language Detection System

A real-time Sign Language Detection and Recognition System built using Python, OpenCV, MediaPipe, and Deep Learning. This project captures hand gestures through a webcam, extracts hand landmarks, and predicts sign language gestures using a trained neural network model.

This project is suitable for:

 Academic / college projects
 Computer Vision beginners
 Assistive technology demonstrations



 ğŸ“Œ Features

 Real-time hand detection using MediaPipe Hands
 Dataset collection using webcam
 Gesture classification using a trained deep learning model
 Modular and easy-to-understand code structure
 Works on standard webcams



 ğŸ› ï¸ Tech Stack

 Programming Language: Python 3
 Libraries & Frameworks:

   OpenCV
   MediaPipe
   NumPy
   TensorFlow / Keras
 IDE: VS Code / Any Python IDE



 ğŸ“‚ Project Structure


SignLanguage-Detection/
â”‚
â”œâ”€â”€ app.py                 Main application file (real-time detection)
â”œâ”€â”€ function.py            Helper functions (MediaPipe, drawing, preprocessing)
â”œâ”€â”€ collectdata.py         Script to collect gesture data using webcam
â”œâ”€â”€ data.py                Dataset handling and label processing
â”œâ”€â”€ trainmodel.py          Model training script
â”œâ”€â”€ model.json             Saved model architecture
â”œâ”€â”€ model.h5               Trained model weights
â”œâ”€â”€ image/                 Images / assets
â”œâ”€â”€ Logs/                  Training logs (ignored in git)
â”œâ”€â”€ MP_Data/               Collected landmark data (ignored in git)
â”œâ”€â”€ requirements.txt       Project dependencies
â””â”€â”€ README.md              Project documentation




 âš™ï¸ Installation & Setup

 1ï¸âƒ£ Clone the Repository

bash
git clone https://github.com/dishak23/SignLanguage-Detection.git
cd SignLanguage-Detection


 2ï¸âƒ£ Create Virtual Environment (Recommended)

bash
python -m venv venv


Activate:

 Windows:

bash
venv\Scripts\activate


 Linux / macOS:

bash
source venv/bin/activate


 3ï¸âƒ£ Install Dependencies

bash
pip install -r requirements.txt




 â–¶ï¸ How to Run

 ğŸ”¹ Collect Training Data

bash
python collectdata.py


 ğŸ”¹ Train the Model

bash
python trainmodel.py


 ğŸ”¹ Run Real-Time Detection

bash
python app.py


Make sure your webcam is connected.



 ğŸ§  How It Works

1. Webcam captures hand gestures
2. MediaPipe extracts 21 hand landmarks
3. Landmarks are preprocessed and passed to the trained model
4. Model predicts the corresponding sign
5. Result is displayed in real-time



 ğŸ“¸ Sample Output

> Real-time webcam feed with detected hand landmarks and predicted sign label.



 ğŸš€ Future Enhancements

 Add support for more gestures
 Convert to full sentence recognition
 Deploy as a web or mobile application
 Improve accuracy using CNN / LSTM models



 ğŸ‘©â€ğŸ’» Author

Disha Karmakar
GitHub: [https://github.com/dishak23](https://github.com/dishak23)



 ğŸ“„ License

This project is for educational purposes. Feel free to use and modify it for learning and academic use.
